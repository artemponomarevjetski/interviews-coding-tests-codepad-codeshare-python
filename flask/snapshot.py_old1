#!/usr/bin/env python3
"""
Periodic screen capture → OCR with Tesseract → GPT API → live Flask dashboard
Using direct HTTP requests to OpenAI API for maximum compatibility
"""

from __future__ import annotations

import os
import platform
import shutil
import socket
import subprocess
import time
import json
from datetime import datetime
from threading import Thread
from typing import Optional

from flask import Flask, render_template_string, send_file
from PIL import Image, ImageEnhance, ImageFilter
import pytesseract
import requests

# ─────────────────────────── Configuration ────────────────────────────
BASE = os.path.expanduser("~/interviews-coding-tests-codepad-codeshare-python")
CONFIG = {
    "save_dir":  f"{BASE}/temp",
    "log_dir":   f"{BASE}/log",
    "log_file":  "snapshot.log",
    "latest":    "snap_latest.png",
    "ocr_txt":   "snapshot.txt",
    "gpt_analysis": "gpt_analysis.txt",
    "port":      5000,
    "interval":  15,
    "retain":    20,
    "tesseract": None,
    "openai_model": "gpt-3.5-turbo",
}
os.makedirs(CONFIG["save_dir"], exist_ok=True)
os.makedirs(CONFIG["log_dir"],  exist_ok=True)

# ─────────────────────────── Helper utilities ─────────────────────────
def log(msg: str) -> None:
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    path = os.path.join(CONFIG["log_dir"], CONFIG["log_file"])
    with open(path, "a") as fh:
        fh.write(f"[{ts}] {msg}\n")
    print(f"[{ts}] {msg}")

# Load API key ONLY from .env file
def load_api_key_from_env_file() -> Optional[str]:
    """Load OpenAI API key ONLY from .env file, ignoring system environment."""
    env_path = os.path.join(os.path.dirname(__file__), '.env')
    if not os.path.exists(env_path):
        log("❌ No .env file found")
        return None
    
    try:
        with open(env_path, 'r') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                if line.startswith('OPENAI_API_KEY='):
                    key = line.split('=', 1)[1].strip()
                    key = key.strip('"\'')
                    if key:
                        log("✅ API key loaded from .env file")
                        return key
                    else:
                        log("❌ Empty API key in .env file")
                        return None
        log("❌ OPENAI_API_KEY not found in .env file")
        return None
    except Exception as e:
        log(f"❌ Error reading .env file: {e}")
        return None

# Initialize API key
api_key = load_api_key_from_env_file()
gpt_enabled = api_key is not None

if gpt_enabled:
    log("✅ GPT features enabled with API key from .env")
else:
    log("⚠️  GPT features disabled - no API key found")

def detect_tesseract() -> bool:
    if CONFIG["tesseract"]:
        return True
    for p in ("/opt/homebrew/bin/tesseract",
              "/usr/local/bin/tesseract",
              "/usr/bin/tesseract",
              shutil.which("tesseract")):
        if p and os.path.exists(p):
            CONFIG["tesseract"] = p
            pytesseract.pytesseract.tesseract_cmd = p
            return True
    return False

def maintain_latest_symlink(new_img: str) -> None:
    link = os.path.join(CONFIG["save_dir"], CONFIG["latest"])
    try:
        if os.path.islink(link) or os.path.exists(link):
            os.unlink(link)
        os.symlink(new_img, link)
    except OSError:
        shutil.copy2(new_img, link)
    shots = sorted(f for f in os.listdir(CONFIG["save_dir"])
                   if f.startswith("snap_") and f.endswith(".png"))
    while len(shots) > CONFIG["retain"]:
        os.remove(os.path.join(CONFIG["save_dir"], shots.pop(0)))

# ────────────────────────── GPT API Integration ───────────────────────
def send_to_gpt_api(ocr_text: str) -> Optional[str]:
    if not ocr_text.strip():
        return "No text extracted from image"
    
    if not gpt_enabled:
        return "GPT analysis unavailable - no API key provided"
    
    try:
        truncated_text = ocr_text[:4000] if len(ocr_text) > 4000 else ocr_text
        
        prompt = f"""
        Analyze the following text extracted from a screenshot. This text may be scattered, incomplete, or contain errors from OCR.
        
        Provide:
        1. A concise summary of the main content
        2. Key insights or notable information
        3. Any actions, tasks, or important details mentioned
        
        Keep your response clear and well-structured.
        
        Extracted text:
        {truncated_text}
        """
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        data = {
            "model": CONFIG["openai_model"],
            "messages": [
                {"role": "system", "content": "You are a helpful assistant that analyzes text extracted from screenshots. Provide clear, concise analysis of the content."},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 500,
            "temperature": 0.3
        }
        
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            analysis = result["choices"][0]["message"]["content"].strip()
            log(f"GPT analysis completed: {len(analysis)} characters")
            return analysis
        else:
            log(f"GPT API error: {response.status_code} - {response.text}")
            return f"GPT analysis failed: {response.status_code}"
        
    except Exception as e:
        log(f"GPT API error: {e}")
        return f"GPT analysis failed: {str(e)}"

# ────────────────────────── Screenshot routines ───────────────────────
def _quartz_capture() -> Optional[str]:
    try:
        from Quartz import (
            CGWindowListCopyWindowInfo, kCGWindowListOptionAll, kCGNullWindowID,
            CGWindowListCreateImage, CGRectInfinite,
            kCGWindowListOptionIncludingWindow, kCGWindowImageBoundsIgnoreFraming,
        )
        onscreen = [w for w in
                    CGWindowListCopyWindowInfo(kCGWindowListOptionAll, kCGNullWindowID)
                    if w.get("kCGWindowIsOnscreen")]
        if not onscreen:
            return None
        win_id = onscreen[0]["kCGWindowNumber"]
        img_ref = CGWindowListCreateImage(
            CGRectInfinite, kCGWindowListOptionIncludingWindow,
            win_id, kCGWindowImageBoundsIgnoreFraming)
        if not img_ref:
            return None
        path = os.path.join(CONFIG["save_dir"],
                            f"snap_quartz_{int(time.time())}.png")
        Image.frombytes("RGBA",
                        (img_ref.getWidth(), img_ref.getHeight()),
                        img_ref.getDataProvider().getData()
                        ).save(path)
        return path
    except Exception as e:
        log(f"Quartz capture failed: {e}")
        return None

def capture_snapshot() -> Optional[str]:
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    img = os.path.join(CONFIG["save_dir"], f"snap_{ts}.png")
    cmds = [
        ["screencapture", "-x", "-l", "-o", img],
        ["screencapture", "-x", "-m", "-o", img],
        ["screencapture", "-x", "-o", img],
    ]
    for cmd in cmds:
        try:
            subprocess.run(cmd, check=True, timeout=10, capture_output=True)
            if os.path.getsize(img) > 0:
                return img
        except Exception:
            pass
    if os.path.exists(img):
        os.remove(img)
    return _quartz_capture() if platform.system() == "Darwin" else None

# ───────────────────────── OCR utilities ───────────────────────────────
def _prep_for_ocr(img: Image.Image) -> Image.Image:
    img = img.convert("L")
    img = ImageEnhance.Contrast(img).enhance(2.0)
    img = img.filter(ImageFilter.SHARPEN)
    return img.point(lambda x: 0 if x < 140 else 255)

def extract_text(path: str) -> str:
    if not detect_tesseract():
        log("Tesseract not found – OCR skipped")
        return ""
    text = ""
    try:
        prepped = _prep_for_ocr(Image.open(path))
        for cfg in ("--oem 3 --psm 6", "--oem 3 --psm 11", "--oem 3 --psm 4"):
            t = pytesseract.image_to_string(prepped, config=cfg)
            if len(t) > len(text):
                text = t
    except Exception as e:
        log(f"OCR error on {path}: {e}")
    return text.strip()

# ───────────────────────── Worker thread ───────────────────────────────
def worker() -> None:
    while True:
        shot = capture_snapshot()
        if not shot:
            log("Screenshot failed")
            time.sleep(CONFIG["interval"])
            continue

        txt = extract_text(shot)
        
        if txt:
            with open(os.path.join(CONFIG["save_dir"], CONFIG["ocr_txt"]), "w") as f:
                f.write(txt)
            
            if gpt_enabled:
                log("Sending OCR text to GPT API...")
                gpt_analysis = send_to_gpt_api(txt)
                
                if gpt_analysis:
                    with open(os.path.join(CONFIG["save_dir"], CONFIG["gpt_analysis"]), "w") as f:
                        f.write(gpt_analysis)
                    log("GPT analysis completed and saved")
                else:
                    log("GPT analysis failed")
            else:
                log("GPT API not available - skipping analysis")
                
            log("Snapshot + OCR succeeded" + (" + GPT analysis" if gpt_enabled else ""))
        else:
            log("Snapshot captured – no text recognised")

        maintain_latest_symlink(shot)
        time.sleep(CONFIG["interval"])

# ──────────────────────────── Flask UI  ────────────────────────────────
TPL = """
<!doctype html>
<title>Screen OCR + GPT Analysis Dashboard</title>
<meta http-equiv="refresh" content="10">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap">
<style>
body{font-family:Inter,Arial,sans-serif;background:#f8f9fa;margin:20px}
.container{max-width:1200px;background:#fff;border-radius:8px;padding:20px;margin:auto;box-shadow:0 2px 10px rgba(0,0,0,.1)}
h1{margin-top:0}
.meta{color:#666;font-size:.9em;margin-bottom:15px}
.status{display:inline-block;padding:4px 10px;border-radius:4px;font-weight:600;color:#fff;background:#4caf50}
.controls{margin:15px 0;display:flex;gap:10px}
.btn{padding:8px 15px;border:0;border-radius:4px;cursor:pointer;font-weight:600;transition:background .3s}
.btn-copy{background:#4caf50;color:#fff}.btn-copy:hover{background:#43a047}
.btn-refresh{background:#2196f3;color:#fff}.btn-refresh:hover{background:#1976d2}
pre{background:#f5f5f5;padding:15px;border-radius:6px;white-space:pre-wrap;max-height:60vh;overflow-y:auto;border:1px solid #ddd}
.imgwrap{text-align:center;margin-top:20px}
.imgwrap img{max-width:100%;border:1px solid #ddd;border-radius:4px}
.alert{position:fixed;bottom:20px;right:20px;background:#4caf50;color:#fff;padding:10px 15px;border-radius:5px;display:none;box-shadow:0 2px 10px rgba(0,0,0,.2)}
.section{margin:20px 0;padding:15px;border-radius:6px}
.section h3{margin-top:0;color:#333}
.gpt-section{background:#e8f5e8;border-left:4px solid #4caf50}
.ocr-section{background:#fff3e0;border-left:4px solid #ff9800}
.warning{background:#fff3cd;border-left:4px solid #ffc107;color:#856404}
.info{background:#d1ecf1;border-left:4px solid #17a2b8;color:#0c5460}
</style>

<div class="container">
  <h1>Screen OCR + GPT Analysis Dashboard</h1>
  <div class="meta">Last updated: {{ts}} | Status: <span class="status">{{status}}</span></div>

  <div class="controls">
    <button class="btn btn-copy" onclick="copyAllText()">Copy All Text</button>
    <button class="btn btn-refresh" onclick="location.reload()">Refresh</button>
  </div>

  {% if not gpt_enabled %}
  <div class="section warning">
    <h3>⚠️ GPT Analysis Disabled</h3>
    <p>OpenAI API key not found in .env file. GPT analysis features are currently disabled.</p>
    <p><small>Add your API key to the .env file: <code>OPENAI_API_KEY='your-api-key'</code></small></p>
  </div>
  {% else %}
  <div class="section info">
    <h3>✅ GPT Analysis Enabled</h3>
    <p>Using model: {{gpt_model}} | Capture interval: {{interval}} seconds</p>
  </div>
  {% endif %}

  {% if gpt_analysis %}
  <div class="section gpt-section">
    <h3>🤖 GPT Analysis:</h3>
    <pre id="gptAnalysis">{{gpt_analysis}}</pre>
  </div>
  {% endif %}

  {% if image %}
  <div class="imgwrap">
    <h3>📸 Latest Screenshot:</h3>
    <img src="/latest_image?{{rand}}" alt="Latest screenshot">
  </div>
  {% endif %}

  {% if text %}
  <div class="section ocr-section">
    <h3>📄 Raw OCR Text:</h3>
    <pre id="ocrText">{{text}}</pre>
  </div>
  {% endif %}

  <div id="copied" class="alert">Text copied ✓</div>
</div>

<script>
function copyAllText(){ 
  const gptText = document.getElementById('gptAnalysis');
  const ocrText = document.getElementById('ocrText');
  let fullText = '';
  
  if (gptText) fullText += '🤖 GPT ANALYSIS:\n' + gptText.textContent + '\n\n';
  if (ocrText) fullText += '📄 RAW OCR TEXT:\n' + ocrText.textContent;
  
  navigator.clipboard.writeText(fullText).then(() => {
    const alert = document.getElementById('copied');
    alert.style.display = 'block';
    setTimeout(() => alert.style.display = 'none', 2000);
  });
}

document.addEventListener('keydown',e=>{
  if(!(e.metaKey||e.ctrlKey)) return;
  if(['c','C'].includes(e.key)) {e.preventDefault();copyAllText();}
});
</script>
"""

app = Flask(__name__)

@app.route("/")
def dashboard():
    txt_path = os.path.join(CONFIG["save_dir"], CONFIG["ocr_txt"])
    gpt_path = os.path.join(CONFIG["save_dir"], CONFIG["gpt_analysis"])
    
    text = ""
    gpt_analysis = ""
    
    try:
        if os.path.exists(txt_path):
            with open(txt_path, "r") as f:
                text = f.read()
    except Exception:
        pass
        
    try:
        if os.path.exists(gpt_path):
            with open(gpt_path, "r") as f:
                gpt_analysis = f.read()
    except Exception:
        pass
    
    latest_img_exists = os.path.exists(os.path.join(CONFIG["save_dir"], CONFIG["latest"]))
    
    return render_template_string(
        TPL,
        ts=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        status="success" if text or gpt_analysis else "waiting",
        text=text,
        gpt_analysis=gpt_analysis,
        gpt_enabled=gpt_enabled,
        gpt_model=CONFIG["openai_model"],
        interval=CONFIG["interval"],
        image=latest_img_exists,
        rand=int(time.time())
    )

@app.route("/latest_image")
def latest_image():
    path = os.path.join(CONFIG["save_dir"], CONFIG["latest"])
    return send_file(path, mimetype="image/png") if os.path.exists(path) else ("No image", 404)

# ───────────────────────────── Main ───────────────────────────────────
if __name__ == "__main__":
    Thread(target=worker, daemon=True).start()
    ip = socket.gethostbyname(socket.gethostname()) or "localhost"
    log(f"🤖 Screen OCR + GPT Analysis Dashboard")
    log(f"📊 Serving on http://{ip}:{CONFIG['port']}")
    log(f"⏰ Capture interval: {CONFIG['interval']} seconds")
    if gpt_enabled:
        log(f"🧠 GPT Model: {CONFIG['openai_model']} - ✅ ENABLED")
        log(f"🔑 Using API key from .env file")
    else:
        log(f"🧠 GPT Features: ❌ DISABLED - No API key in .env file")
    app.run(host="0.0.0.0", port=CONFIG["port"], debug=False)