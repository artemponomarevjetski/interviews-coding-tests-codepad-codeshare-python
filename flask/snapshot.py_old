#!/usr/bin/env python3
"""
ULTRA-FAST Screen OCR + Content Analyzer
- 5-second snapshots with timestamps
- Aggregate conversation log
- Auto-GPT every 2 seconds when content changes
- Instant manual prompts
- Auto-balance update every 10 minutes
"""

import os
import platform
import shutil
import socket
import subprocess
import time
import signal
import sys
import psutil
from datetime import datetime
from threading import Thread, Lock

from flask import Flask, render_template_string, send_file, jsonify
from PIL import Image, ImageEnhance, ImageFilter
import pytesseract
import requests

# Configuration - ULTRA FAST
BASE = os.path.expanduser("~/interviews-coding-tests-codepad-codeshare-python")
CONFIG = {
    "save_dir": f"{BASE}/temp",
    "log_dir": f"{BASE}/log", 
    "log_file": "snapshot.log",
    "aggregate_log": "aggregate_conversation.txt",  # NEW: Aggregate conversation log
    "latest": "snap_latest.png",
    "ocr_txt": "snapshot.txt",
    "gpt_analysis": "gpt_analysis.txt",
    "port": 5000,
    "interval": 5,  # ‚ö° ULTRA FAST: 5 seconds between captures
    "gpt_interval": 2,  # ‚ö° Auto-GPT every 2 seconds when content changes
    "balance_interval": 600,  # ‚ö° Auto-balance update every 10 minutes (600 seconds)
    "retain": 50,   # Keep more screenshots
    "tesseract": None,
    "openai_model": "gpt-4",
}
os.makedirs(CONFIG["save_dir"], exist_ok=True)
os.makedirs(CONFIG["log_dir"], exist_ok=True)

# Global control variables
worker_running = True
app_running = True
control_lock = Lock()
last_api_call_time = None
last_api_content_preview = ""
total_api_cost = 0.0
current_balance = "$9.40"  # Default fallback balance
api_key = None  # Will be loaded later
last_text_hash = ""  # For detecting content changes
conversation_history = []  # NEW: Store conversation history

def clear_logs_on_startup():
    """Clear log files when starting the application"""
    log_path = os.path.join(CONFIG["log_dir"], CONFIG["log_file"])
    try:
        if os.path.exists(log_path):
            with open(log_path, 'w') as f:
                f.write(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] üîÑ Logs cleared on startup\n")
        print("‚úÖ Logs cleared on startup")
    except Exception as e:
        print(f"‚ùå Error clearing logs: {e}")

def log(msg: str):
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    path = os.path.join(CONFIG["log_dir"], CONFIG["log_file"])
    with open(path, "a") as fh:
        fh.write(f"[{ts}] {msg}\n")
    print(f"[{ts}] {msg}")

# NEW: Aggregate conversation logging
def log_conversation(role: str, content: str, content_type: str = "text"):
    """Log to aggregate conversation file"""
    global conversation_history
    
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    conversation_entry = {
        "timestamp": ts,
        "role": role,
        "content": content,
        "type": content_type
    }
    
    # Add to in-memory history (keep last 100 entries)
    conversation_history.append(conversation_entry)
    if len(conversation_history) > 100:
        conversation_history.pop(0)
    
    # Append to file
    aggregate_path = os.path.join(CONFIG["log_dir"], CONFIG["aggregate_log"])
    try:
        with open(aggregate_path, "a", encoding="utf-8") as f:
            f.write(f"\n{'='*80}\n")
            f.write(f"üïí {ts} | {role.upper()} | {content_type.upper()}\n")
            f.write(f"{'='*80}\n")
            f.write(f"{content}\n")
    except Exception as e:
        log(f"‚ùå Error writing to aggregate log: {e}")

# Load API key FIRST
def load_api_key_from_env_file():
    """Load OpenAI API key from .env file"""
    env_path = os.path.join(os.path.dirname(__file__), '.env')
    if not os.path.exists(env_path):
        return None
    try:
        with open(env_path, 'r') as f:
            for line in f:
                if line.startswith('OPENAI_API_KEY='):
                    key = line.split('=', 1)[1].strip().strip('"\'')
                    if key:
                        log(f"‚úÖ API key loaded from .env file: {key[:10]}...{key[-5:]}")
                        return key
        return None
    except Exception as e:
        log(f"‚ùå Error reading .env: {e}")
        return None

# Initialize API key immediately
api_key = load_api_key_from_env_file()
gpt_enabled = api_key is not None

if gpt_enabled:
    log("‚úÖ GPT-4 features enabled")
else:
    log("‚ö†Ô∏è GPT features disabled")

# Balance functions
def get_balance_from_api():
    """Get current OpenAI balance from API or use fallback"""
    global current_balance, api_key
    
    if not api_key:
        log("‚ö†Ô∏è No API key available, using fallback balance")
        return "$9.40"  # Fallback balance
    
    try:
        headers = {
            "Authorization": f"Bearer {api_key}"
        }
        
        # Try to get billing information
        response = requests.get(
            "https://api.openai.com/dashboard/billing/credit_grants",
            headers=headers,
            timeout=10
        )
        
        if response.status_code == 200:
            billing_data = response.json()
            total_granted = billing_data.get('total_granted', 0)
            total_used = billing_data.get('total_used', 0)
            remaining = total_granted - total_used
            new_balance = f"${remaining:.2f}"
            log(f"üí∞ Balance from billing API: {new_balance}")
            return new_balance
        else:
            # Fallback to usage API
            today = datetime.now().strftime("%Y-%m-%d")
            response = requests.get(
                f"https://api.openai.com/v1/usage?date={today}",
                headers=headers,
                timeout=10
            )
            if response.status_code == 200:
                usage_data = response.json()
                total_usage = usage_data.get('total_usage', 0) / 100
                estimated_balance = max(0, 10.00 - total_usage)
                new_balance = f"${estimated_balance:.2f}"
                log(f"üí∞ Balance from usage API: {new_balance}")
                return new_balance
            else:
                log(f"‚ö†Ô∏è Could not fetch balance from API (Status: {response.status_code}), using fallback")
                return "$9.40"  # Fallback
                
    except Exception as e:
        log(f"‚ö†Ô∏è Balance API error: {e}, using fallback")
        return "$9.40"  # Fallback balance

def get_openai_balance():
    """Get current OpenAI balance - returns string value"""
    global current_balance
    return current_balance

def get_openai_pricing():
    """Get current OpenAI pricing information"""
    pricing = {
        "gpt-4": {"input": 0.03, "output": 0.06},  # per 1K tokens
        "gpt-4-turbo-preview": {"input": 0.01, "output": 0.03},
        "gpt-3.5-turbo": {"input": 0.0015, "output": 0.002},
    }
    return pricing.get(CONFIG["openai_model"], {"input": 0.03, "output": 0.06})

def estimate_cost(text):
    """Estimate cost for processing text"""
    pricing = get_openai_pricing()
    # Rough estimate: 1 token ‚âà 4 characters for English text
    estimated_tokens = len(text) / 4
    cost = (estimated_tokens / 1000) * pricing["input"]
    return max(0.01, cost)  # Minimum $0.01

def get_estimated_requests():
    """Calculate estimated remaining GPT-4 requests"""
    try:
        balance_clean = current_balance.replace('$', '').strip()
        balance_float = float(balance_clean)
        pricing = get_openai_pricing()
        avg_cost_per_call = 0.03  # Average cost per analysis
        estimated = int(balance_float / avg_cost_per_call)
        return max(0, estimated)
    except:
        return 300

def get_python_processes():
    """Get current Python processes in the system"""
    try:
        python_processes = []
        for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'memory_info']):
            try:
                if 'python' in proc.info['name'].lower():
                    cmdline = ' '.join(proc.info['cmdline'] or [])
                    memory_mb = proc.info['memory_info'].rss / 1024 / 1024 if proc.info['memory_info'] else 0
                    
                    python_processes.append({
                        'pid': proc.info['pid'],
                        'name': proc.info['name'],
                        'cmdline': cmdline[:200] + '...' if len(cmdline) > 200 else cmdline,
                        'memory_mb': round(memory_mb, 1)
                    })
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
        
        python_processes.sort(key=lambda x: x['memory_mb'], reverse=True)
        return python_processes
    except Exception as e:
        return [{'error': f'Failed to get processes: {str(e)}'}]

def get_system_info():
    """Get system information"""
    try:
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        memory_used = memory.used / 1024 / 1024 / 1024
        memory_total = memory.total / 1024 / 1024 / 1024
        memory_percent = memory.percent
        disk = psutil.disk_usage('.')
        disk_used = disk.used / 1024 / 1024 / 1024
        disk_total = disk.total / 1024 / 1024 / 1024
        disk_percent = disk.percent
        
        return {
            'cpu_percent': round(cpu_percent, 1),
            'memory_used_gb': round(memory_used, 1),
            'memory_total_gb': round(memory_total, 1),
            'memory_percent': round(memory_percent, 1),
            'disk_used_gb': round(disk_used, 1),
            'disk_total_gb': round(disk_total, 1),
            'disk_percent': round(disk_percent, 1)
        }
    except Exception as e:
        return {'error': f'Failed to get system info: {str(e)}'}

def detect_tesseract():
    if CONFIG["tesseract"]:
        return True
    for p in ("/opt/homebrew/bin/tesseract", "/usr/local/bin/tesseract", 
              "/usr/bin/tesseract", shutil.which("tesseract")):
        if p and os.path.exists(p):
            CONFIG["tesseract"] = p
            pytesseract.pytesseract.tesseract_cmd = p
            return True
    return False

def maintain_latest_symlink(new_img):
    link = os.path.join(CONFIG["save_dir"], CONFIG["latest"])
    try:
        if os.path.islink(link) or os.path.exists(link):
            os.unlink(link)
        os.symlink(new_img, link)
    except OSError:
        shutil.copy2(new_img, link)
    shots = sorted(f for f in os.listdir(CONFIG["save_dir"])
                   if f.startswith("snap_") and f.endswith(".png"))
    while len(shots) > CONFIG["retain"]:
        os.remove(os.path.join(CONFIG["save_dir"], shots.pop(0)))

# GPT API function - optimized for manual prompts with cost tracking
def send_to_gpt_api(ocr_text: str, auto_mode: bool = False) -> str:
    global last_api_call_time, last_api_content_preview, total_api_cost, current_balance
    
    if not ocr_text.strip():
        return "No text extracted from image"
    
    if not gpt_enabled:
        return "GPT analysis unavailable"
    
    try:
        truncated_text = ocr_text[:2500]
        last_api_content_preview = truncated_text[:100] + "..." if len(truncated_text) > 100 else truncated_text
        last_api_call_time = datetime.now()
        
        # Estimate cost before making the call
        estimated_cost = estimate_cost(truncated_text)
        content_type = "Python code/technical content" if any(keyword in ocr_text.lower() for keyword in ["python", "def ", "import ", "function", "code"]) else "general content"
        
        mode_label = "AUTO" if auto_mode else "MANUAL"
        log(f"üì§ {mode_label} PROMPT TO GPT-4: {len(ocr_text)} chars of {content_type} (est. cost: ${estimated_cost:.3f})")
        
        # Log input to conversation
        log_conversation("user", truncated_text, "screenshot_ocr")
        
        prompt = f"""
SCREENSHOT CONTENT:
{truncated_text}

TASK: Analyze this content and provide helpful analysis or solutions.

If this contains:
- Python code ‚Üí Provide complete working solution with explanation
- Technical questions ‚Üí Explain concepts and provide correct answers  
- General content ‚Üí Summarize and analyze key points

RESPONSE FORMAT:
- Start with "ANALYSIS:" or "SOLUTION:"
- Use clear headings and code blocks where appropriate
- Provide explanations and context"""

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        data = {
            "model": CONFIG["openai_model"],
            "messages": [
                {
                    "role": "system", 
                    "content": "You are a helpful technical assistant. Analyze the provided content and provide useful solutions, explanations, or summaries as appropriate."
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            "max_tokens": 1200,
            "temperature": 0.1
        }
        
        log(f"üì® Sending prompt to GPT-4 API...")
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            analysis = result["choices"][0]["message"]["content"].strip()
            
            # Calculate actual cost from response
            usage = result.get("usage", {})
            input_tokens = usage.get("prompt_tokens", 0)
            output_tokens = usage.get("completion_tokens", 0)
            pricing = get_openai_pricing()
            actual_cost = (input_tokens / 1000 * pricing["input"]) + (output_tokens / 1000 * pricing["output"])
            total_api_cost += actual_cost
            
            # Update balance
            try:
                balance_clean = current_balance.replace('$', '').strip()
                balance_float = float(balance_clean)
                new_balance = max(0.0, balance_float - actual_cost)
                current_balance = f"${new_balance:.2f}"
                log(f"üí∞ Balance updated: ${balance_float:.2f} ‚Üí {current_balance}")
            except Exception as e:
                log(f"‚ö†Ô∏è Error updating balance: {e}")
            
            # Log response to conversation
            log_conversation("assistant", analysis, "gpt_analysis")
            
            log(f"‚úÖ GPT-4 analysis SUCCESS: {len(analysis)} characters (Cost: ${actual_cost:.3f}, Total: ${total_api_cost:.3f})")
            return analysis
            
        else:
            error_msg = f"API Error {response.status_code}"
            if response.status_code == 429:
                error_msg += " - Rate limit exceeded. Please wait and try again."
            elif response.status_code == 401:
                error_msg += " - Invalid API key. Please check your .env file."
            elif response.status_code == 402:
                error_msg += " - Insufficient credits. Please check your balance."
            
            log(f"‚ùå GPT-4 API error {response.status_code}: {response.text}")
            return f"{error_msg}. Please try again."
        
    except Exception as e:
        log(f"‚ùå GPT-4 API error: {e}")
        return f"API Error: {e}. Please try again."

# Screenshot functions
def capture_snapshot():
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    img = os.path.join(CONFIG["save_dir"], f"snap_{ts}.png")
    cmds = [
        ["screencapture", "-x", "-l", "-o", img],
        ["screencapture", "-x", "-m", "-o", img], 
        ["screencapture", "-x", "-o", img],
    ]
    for cmd in cmds:
        try:
            subprocess.run(cmd, check=True, timeout=5, capture_output=True)  # Faster timeout
            if os.path.getsize(img) > 0:
                return img
        except Exception:
            pass
    if os.path.exists(img):
        os.remove(img)
    return None

def _prep_for_ocr(img):
    img = img.convert("L")
    img = ImageEnhance.Contrast(img).enhance(2.0)
    img = img.filter(ImageFilter.SHARPEN)
    return img.point(lambda x: 0 if x < 140 else 255)

def extract_text(path):
    if not detect_tesseract():
        return ""
    text = ""
    try:
        prepped = _prep_for_ocr(Image.open(path))
        for cfg in ("--oem 3 --psm 6", "--oem 3 --psm 11"):
            t = pytesseract.image_to_string(prepped, config=cfg)
            if len(t) > len(text):
                text = t
    except Exception as e:
        log(f"‚ùå OCR error: {e}")
    return text.strip()

# NEW: Auto-balance updater thread
def balance_updater():
    """Update balance automatically every 10 minutes"""
    while worker_running:
        try:
            time.sleep(CONFIG["balance_interval"])  # 10 minutes
            if worker_running:
                global current_balance
                new_balance = get_balance_from_api()
                current_balance = new_balance
                log(f"üîÑ AUTO-BALANCE UPDATE: {new_balance}")
        except Exception as e:
            log(f"‚ùå Auto-balance update error: {e}")

# Worker thread - ULTRA FAST with auto-GPT
def worker():
    global last_text_hash
    last_gpt_call_time = 0
    
    while worker_running:
        shot = capture_snapshot()
        if not shot:
            if worker_running:
                time.sleep(CONFIG["interval"])
            continue

        txt = extract_text(shot)
        current_hash = hash(txt) if txt else ""
        
        if txt:
            with open(os.path.join(CONFIG["save_dir"], CONFIG["ocr_txt"]), "w") as f:
                f.write(txt)
            
            # Log OCR text to conversation
            log_conversation("system", f"OCR extracted {len(txt)} characters", "ocr_result")
            
            # AUTO-GPT: Send to GPT if content changed and enough time passed
            current_time = time.time()
            if (current_hash != last_text_hash and 
                gpt_enabled and 
                (current_time - last_gpt_call_time) >= CONFIG["gpt_interval"]):
                
                log("üéØ AUTO-GPT: Content changed, sending to GPT-4...")
                gpt_analysis = send_to_gpt_api(txt, auto_mode=True)
                
                if gpt_analysis and not gpt_analysis.startswith("API Error"):
                    with open(os.path.join(CONFIG["save_dir"], CONFIG["gpt_analysis"]), "w") as f:
                        f.write(gpt_analysis)
                    last_gpt_call_time = current_time
                
                last_text_hash = current_hash
            
            if worker_running:
                log(f"üì∏ OCR extracted {len(txt)} characters | Next GPT in {CONFIG['gpt_interval']}s")
        else:
            if worker_running:
                log("üì∏ No text extracted")

        if worker_running:
            maintain_latest_symlink(shot)
            time.sleep(CONFIG["interval"])
    
    log("üëã Worker thread stopped")

# Flask UI - Updated for ultra-fast mode
TPL = """
<!doctype html>
<title>‚ö° ULTRA-FAST Content Analyzer</title>
<meta http-equiv="refresh" content="5">
<style>
body{font-family:Inter,Arial,sans-serif;background:#f8f9fa;margin:20px}
.container{max-width:1200px;background:#fff;border-radius:8px;padding:20px;margin:auto;box-shadow:0 2px 10px rgba(0,0,0,.1)}
h1{margin-top:0}
.meta{color:#666;font-size:.9em;margin-bottom:15px}
.status{display:inline-block;padding:4px 10px;border-radius:4px;font-weight:600;color:#fff;background:#4caf50}
.controls{margin:15px 0;display:flex;gap:10px;flex-wrap:wrap}
.btn{padding:8px 15px;border:0;border-radius:4px;cursor:pointer;font-weight:600;text-decoration:none}
.btn-copy{background:#4caf50;color:#fff}
.btn-refresh{background:#2196f3;color:#fff}
.btn-prompt{background:#28a745;color:#fff}
.btn-kill{background:#dc3545;color:#fff}
.btn-billing{background:#6f42c1;color:#fff}
.btn-refresh-balance{background:#17a2b8;color:#fff}
.btn:disabled{opacity:0.6;cursor:not-allowed}
.btn:hover:not(:disabled){opacity:0.9;transform:translateY(-1px)}
pre{background:#f5f5f5;padding:15px;border-radius:6px;white-space:pre-wrap;max-height:60vh;overflow-y:auto;border:1px solid #ddd;font-family:monospace}
.imgwrap{text-align:center;margin-top:20px}
.imgwrap img{max-width:100%;border:1px solid #ddd;border-radius:4px}
.balance-info{background:#d4edda;border-left:4px solid #28a745;color:#155724;padding:15px;border-radius:6px;margin:15px 0}
.system-info{background:#e2e3e5;border-left:4px solid #6c757d;color:#383d41;padding:15px;border-radius:6px;margin:15px 0}
.process-info{background:#fff3cd;border-left:4px solid #ffc107;color:#856404;padding:15px;border-radius:6px;margin:15px 0}
.warning{background:#fff3cd;border-left:4px solid #ffc107;color:#856404;padding:15px;border-radius:6px;margin:15px 0}
.error{background:#f8d7da;border-left:4px solid #dc3545;color:#721c24;padding:15px;border-radius:6px;margin:15px 0}
.success{background:#d4edda;border-left:4px solid #28a745;color:#155724;padding:15px;border-radius:6px;margin:15px 0}
.ultra-fast{background:#e3f2fd;border-left:4px solid #2196f3;color:#0d47a1;padding:15px;border-radius:6px;margin:15px 0}
.shutdown-message{background:#dc3545;color:white;padding:20px;border-radius:8px;text-align:center;margin:20px 0}
.process-table{width:100%;border-collapse:collapse;margin:10px 0}
.process-table th, .process-table td{padding:8px;text-align:left;border-bottom:1px solid #ddd}
.process-table th{background:#f8f9fa;font-weight:600}
.process-table tr:hover{background:#f5f5f5}
.process-table .cmd-cell{max-width:400px;word-wrap:break-word;word-break:break-all;white-space:normal;font-family:monospace;font-size:0.8em}
.system-stats{display:grid;grid-template-columns:repeat(auto-fit, minmax(200px, 1fr));gap:15px;margin:15px 0}
.stat-box{background:#f8f9fa;padding:15px;border-radius:6px;text-align:center;border:1px solid #e9ecef}
.stat-value{font-size:1.5em;font-weight:bold;color:#007bff}
.stat-label{font-size:0.9em;color:#6c757d;margin-top:5px}
.api-status{background:#e7f3ff;border-left:4px solid #2196f3;color:#0c5460;padding:10px;border-radius:6px;margin:10px 0;font-size:0.9em}
.gpt-ready{background:#d4edda;border-left:4px solid #28a745;color:#155724;padding:15px;border-radius:6px;margin:15px 0}
.cost-info{background:#fff3cd;border-left:4px solid #ffc107;color:#856404;padding:10px;border-radius:6px;margin:10px 0;font-size:0.9em}
.auto-mode{background:#fff3cd;border-left:4px solid #ff9800;color:#e65100;padding:10px;border-radius:6px;margin:10px 0;font-size:0.9em}
</style>

<div class="container">
  <h1>‚ö° ULTRA-FAST Content Analyzer</h1>
  <div class="meta">Last updated: {{ts}} | Status: <span class="status">{{status}}</span></div>

  <div class="controls">
    <button class="btn btn-copy" onclick="copyAllText()">Copy All Text</button>
    <button class="btn btn-refresh" onclick="location.reload()">Refresh</button>
    <button class="btn btn-prompt" onclick="sendPrompt()" id="promptBtn">üöÄ INSTANT Prompt to GPT</button>
    <button class="btn btn-refresh-balance" onclick="refreshBalance()">üîÑ Refresh Balance</button>
    <button class="btn btn-kill" onclick="killApp()">üíÄ Kill App & Close</button>
    <a href="https://platform.openai.com/account/billing" target="_blank" class="btn btn-billing">üí∞ Check Usage</a>
  </div>

  <!-- ULTRA-FAST Mode Info -->
  <div class="ultra-fast">
    <h3>‚ö° ULTRA-FAST MODE ACTIVE</h3>
    <p><strong>Snapshots:</strong> Every {{interval}} seconds with timestamps</p>
    <p><strong>Auto-GPT:</strong> Every {{gpt_interval}} seconds when content changes</p>
    <p><strong>Manual Prompts:</strong> Instant processing</p>
    <p><strong>Balance Updates:</strong> Automatic every 10 minutes</p>
    <p><strong>Aggregate Log:</strong> log/aggregate_conversation.txt</p>
  </div>

  <!-- Balance Information -->
  <div class="balance-info">
    <h3>üí∞ OpenAI Balance: {{balance}}</h3>
    <p><strong>Auto-recharge:</strong> Enabled (recharges to $10.00 when balance reaches $5.00)</p>
    <p><strong>Monthly recharge limit:</strong> $20.00</p>
    <p><em>GPT-4: ~$0.03 per 1K tokens | Screenshots/OCR: Free</em></p>
    <p><strong>Remaining credits:</strong> {{balance}} (enough for ~{{estimated_requests}} GPT-4 requests)</p>
    {% if total_cost > 0 %}
    <div class="cost-info">
      <strong>Session API Cost:</strong> ${{ "%.3f"|format(total_cost) }}
    </div>
    {% endif %}
  </div>

  {% if gpt_enabled %}
  <div class="gpt-ready">
    <h3>üü¢ GPT-4 READY - ULTRA FAST</h3>
    <p><strong>Mode:</strong> Auto-GPT every {{gpt_interval}}s + Instant manual prompts</p>
    <p><strong>Model:</strong> {{gpt_model}} | <strong>Cost:</strong> ~$0.03 per analysis</p>
    <p><strong>Last Analysis:</strong> {{last_api_time}}</p>
    <p><strong>Last Content:</strong> {{last_content_preview}}</p>
    {% if auto_gpt_active %}
    <div class="auto-mode">
      <strong>üîÑ AUTO-GPT ACTIVE:</strong> Analyzing content changes every {{gpt_interval}} seconds
    </div>
    {% endif %}
  </div>
  {% else %}
  <div class="warning">
    <h3>‚ö†Ô∏è GPT Analysis Disabled</h3>
    <p>OpenAI API key not found in .env file</p>
  </div>
  {% endif %}

  <!-- System Information -->
  <div class="system-info">
    <h3>üñ•Ô∏è System Information</h3>
    <div class="system-stats">
      <div class="stat-box">
        <div class="stat-value">{{system_info.cpu_percent}}%</div>
        <div class="stat-label">CPU Usage</div>
      </div>
      <div class="stat-box">
        <div class="stat-value">{{system_info.memory_used_gb}}/{{system_info.memory_total_gb}} GB</div>
        <div class="stat-label">Memory ({{system_info.memory_percent}}%)</div>
      </div>
      <div class="stat-box">
        <div class="stat-value">{{system_info.disk_used_gb}}/{{system_info.disk_total_gb}} GB</div>
        <div class="stat-label">Disk ({{system_info.disk_percent}}%)</div>
      </div>
    </div>
  </div>

  <!-- Python Processes -->
  <div class="process-info">
    <h3>üêç Current Python Processes ({{python_processes|length}})</h3>
    {% if python_processes and python_processes[0] is mapping %}
    <table class="process-table">
      <thead>
        <tr>
          <th>PID</th>
          <th>Process</th>
          <th>Memory</th>
          <th>Command</th>
        </tr>
      </thead>
      <tbody>
        {% for proc in python_processes %}
        <tr>
          <td><code>{{proc.pid}}</code></td>
          <td><strong>{{proc.name}}</strong></td>
          <td>{{proc.memory_mb}} MB</td>
          <td class="cmd-cell"><small>{{proc.cmdline}}</small></td>
        </tr>
        {% endfor %}
      </tbody>
    </table>
    {% else %}
    <p>No Python processes found or error retrieving process information.</p>
    {% endif %}
  </div>

  {% if gpt_analysis %}
    {% if "error" in gpt_analysis.lower() or "429" in gpt_analysis %}
    <div class="error">
      <h3>‚ùå Analysis Failed</h3>
      <pre id="gptAnalysis">{{gpt_analysis}}</pre>
    </div>
    {% else %}
    <div class="success">
      <h3>‚úÖ GPT-4 Analysis Result:</h3>
      <pre id="gptAnalysis">{{gpt_analysis}}</pre>
    </div>
    {% endif %}
  {% endif %}

  {% if image %}
  <div class="imgwrap">
    <h3>üì∏ Latest Screenshot:</h3>
    <img src="/latest_image?{{rand}}" alt="Latest screenshot">
  </div>
  {% endif %}

  {% if text %}
  <div class="system-info">
    <h3>üìÑ Raw OCR Text:</h3>
    <pre id="ocrText">{{text}}</pre>
  </div>
  {% endif %}
</div>

<script>
// FIXED: Copy All Text function
function copyAllText(){ 
    console.log('üìã Copy All Text clicked');
    
    const gptText = document.getElementById('gptAnalysis');
    const ocrText = document.getElementById('ocrText');
    let fullText = '';
    
    if (gptText) {
        console.log('Found GPT analysis text');
        fullText += 'üîç GPT-4 ANALYSIS RESULT:\\n' + gptText.textContent + '\\n\\n';
    }
    
    if (ocrText) {
        console.log('Found OCR text');
        fullText += 'üìÑ RAW OCR TEXT:\\n' + ocrText.textContent;
    }
    
    if (!fullText.trim()) {
        alert('No text available to copy!');
        return;
    }
    
    // Use modern clipboard API
    navigator.clipboard.writeText(fullText).then(() => {
        console.log('‚úÖ Text copied to clipboard successfully');
        showNotification('‚úÖ All text copied to clipboard!', 'success');
    }).catch(err => {
        console.error('‚ùå Failed to copy text: ', err);
        // Fallback for older browsers
        const textArea = document.createElement('textarea');
        textArea.value = fullText;
        document.body.appendChild(textArea);
        textArea.select();
        try {
            document.execCommand('copy');
            console.log('‚úÖ Text copied using fallback method');
            showNotification('‚úÖ All text copied to clipboard!', 'success');
        } catch (fallbackErr) {
            console.error('‚ùå Fallback copy failed: ', fallbackErr);
            showNotification('‚ùå Failed to copy text', 'error');
        }
        document.body.removeChild(textArea);
    });
}

// FIXED: Send Prompt function - INSTANT
function sendPrompt() {
    console.log('üöÄ INSTANT Prompt to GPT clicked');
    const button = document.getElementById('promptBtn');
    
    // Show loading state
    button.disabled = true;
    button.innerHTML = '‚ö° Sending INSTANTLY...';
    
    fetch('/manual_prompt', { 
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
        }
    })
    .then(response => {
        console.log('Response status:', response.status);
        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }
        return response.json();
    })
    .then(data => {
        console.log('API Response:', data);
        if (data.success) {
            showNotification('‚úÖ GPT-4 analysis completed INSTANTLY! Refreshing...', 'success');
            // Refresh to show new analysis
            setTimeout(() => {
                location.reload();
            }, 500);
        } else {
            showNotification('‚ùå Analysis failed: ' + data.error, 'error');
            button.disabled = false;
            button.innerHTML = 'üöÄ INSTANT Prompt to GPT';
        }
    })
    .catch(error => {
        console.error('Prompt error:', error);
        showNotification('‚ùå Error: ' + error, 'error');
        button.disabled = false;
        button.innerHTML = 'üöÄ INSTANT Prompt to GPT';
    });
}

// NEW: Refresh Balance function
function refreshBalance() {
    console.log('üîÑ Refresh Balance clicked');
    const button = document.querySelector('.btn-refresh-balance');
    button.disabled = true;
    button.innerHTML = 'üîÑ Refreshing...';
    
    fetch('/refresh_balance', { 
        method: 'POST',
        headers: {'Content-Type': 'application/json'}
    })
    .then(response => response.json())
    .then(data => {
        if (data.success) {
            showNotification('‚úÖ Balance updated: ' + data.new_balance, 'success');
            setTimeout(() => location.reload(), 1000);
        } else {
            showNotification('‚ùå ' + data.error, 'error');
        }
        button.disabled = false;
        button.innerHTML = 'üîÑ Refresh Balance';
    })
    .catch(error => {
        showNotification('‚ùå Error refreshing balance', 'error');
        button.disabled = false;
        button.innerHTML = 'üîÑ Refresh Balance';
    });
}

// FIXED: Kill App function
function killApp() {
    console.log('üíÄ Kill App clicked');
    if (confirm('üö® This will KILL the entire application and close this page. Continue?')) {
        const button = document.querySelector('.btn-kill');
        button.disabled = true;
        button.innerHTML = 'üíÄ Shutting down...';
        
        fetch('/kill', { method: 'POST' })
        .then(response => {
            console.log('Kill response received');
            if (!response.ok) {
                throw new Error('Kill request failed');
            }
            return response.json();
        })
        .then(data => {
            console.log('Kill successful:', data);
            document.body.innerHTML = `
                <div class="shutdown-message">
                    <h1>üíÄ Application Shutting Down</h1>
                    <p>The Content Analyzer is being terminated...</p>
                    <p>You can safely close this tab.</p>
                </div>
            `;
            setTimeout(() => {
                window.close();
            }, 2000);
        })
        .catch(error => {
            console.error('Kill error:', error);
            document.body.innerHTML = `
                <div class="shutdown-message">
                    <h1>üíÄ Application Stopped</h1>
                    <p>The server has been terminated.</p>
                    <p>You can safely close this tab.</p>
                </div>
            `;
            setTimeout(() => {
                window.close();
            }, 2000);
        });
    }
}

function showNotification(message, type) {
    console.log('üì¢ Notification:', message);
    const notification = document.createElement('div');
    notification.style.cssText = `
        position: fixed;
        top: 20px;
        right: 20px;
        padding: 15px 20px;
        border-radius: 6px;
        color: white;
        font-weight: bold;
        z-index: 10000;
        background: ${type === 'success' ? '#28a745' : '#dc3545'};
        box-shadow: 0 4px 12px rgba(0,0,0,0.3);
    `;
    notification.textContent = message;
    
    document.body.appendChild(notification);
    
    setTimeout(() => {
        notification.remove();
    }, 3000);
}

// Debug info
console.log('‚úÖ JavaScript loaded successfully');
console.log('‚úÖ Copy All Text function available');
console.log('‚úÖ INSTANT Send Prompt function available');
console.log('‚úÖ Refresh Balance function available');
console.log('‚úÖ Kill App function available');
</script>
"""

app = Flask(__name__)

@app.route("/")
def dashboard():
    if not app_running:
        return "Application is shutting down...", 503
    
    txt_path = os.path.join(CONFIG["save_dir"], CONFIG["ocr_txt"])
    gpt_path = os.path.join(CONFIG["save_dir"], CONFIG["gpt_analysis"])
    
    text = ""
    gpt_analysis = ""
    
    try:
        if os.path.exists(txt_path):
            with open(txt_path, "r") as f:
                text = f.read()
    except: pass
        
    try:
        if os.path.exists(gpt_path):
            with open(gpt_path, "r") as f:
                gpt_analysis = f.read()
    except: pass
    
    latest_img_exists = os.path.exists(os.path.join(CONFIG["save_dir"], CONFIG["latest"]))
    
    # Get additional information
    balance = get_openai_balance()
    python_processes = get_python_processes()
    system_info = get_system_info()
    estimated_requests = get_estimated_requests()
    
    # Format last API call time
    last_api_time = "Never" if last_api_call_time is None else last_api_call_time.strftime("%Y-%m-%d %H:%M:%S")
    last_content_preview = last_api_content_preview if last_api_content_preview else "No content analyzed yet"
    
    return render_template_string(
        TPL,
        ts=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        status="success" if text or gpt_analysis else "waiting",
        text=text,
        gpt_analysis=gpt_analysis,
        gpt_enabled=gpt_enabled,
        gpt_model=CONFIG["openai_model"],
        interval=CONFIG["interval"],
        gpt_interval=CONFIG["gpt_interval"],
        image=latest_img_exists,
        balance=balance,
        python_processes=python_processes,
        system_info=system_info,
        estimated_requests=estimated_requests,
        last_api_time=last_api_time,
        last_content_preview=last_content_preview,
        total_cost=total_api_cost,
        auto_gpt_active=gpt_enabled,
        rand=int(time.time())
    )

@app.route("/latest_image")
def latest_image():
    if not app_running:
        return "Application is shutting down...", 503
    path = os.path.join(CONFIG["save_dir"], CONFIG["latest"])
    return send_file(path, mimetype="image/png") if os.path.exists(path) else ("No image", 404)

@app.route("/manual_prompt", methods=["POST"])
def manual_prompt():
    """Manual prompt endpoint - sends current OCR text to GPT-4 INSTANTLY"""
    try:
        txt_path = os.path.join(CONFIG["save_dir"], CONFIG["ocr_txt"])
        if not os.path.exists(txt_path):
            return jsonify({"success": False, "error": "No OCR text available. Wait for a screenshot first."})
        
        with open(txt_path, "r") as f:
            ocr_text = f.read()
        
        if not ocr_text.strip():
            return jsonify({"success": False, "error": "No text in current screenshot."})
        
        log("üöÄ INSTANT MANUAL PROMPT: User clicked 'Send Prompt to GPT Now'")
        gpt_analysis = send_to_gpt_api(ocr_text, auto_mode=False)
        
        # Save the analysis
        with open(os.path.join(CONFIG["save_dir"], CONFIG["gpt_analysis"]), "w") as f:
            f.write(gpt_analysis)
        
        return jsonify({"success": True, "message": "Analysis completed INSTANTLY"})
        
    except Exception as e:
        log(f"‚ùå Manual prompt error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route("/refresh_balance", methods=["POST"])
def refresh_balance():
    """Refresh the OpenAI balance from API"""
    global current_balance
    try:
        old_balance = current_balance
        new_balance = get_balance_from_api()
        current_balance = new_balance  # Update global balance
        return jsonify({
            "success": True, 
            "old_balance": old_balance, 
            "new_balance": new_balance,
            "message": f"Balance updated: {old_balance} ‚Üí {new_balance}"
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route("/kill", methods=["POST"])
def kill_app():
    """Kill the application - FIXED version"""
    try:
        log("üíÄ Kill request received from web interface")
        global worker_running, app_running
        worker_running = False
        app_running = False
        
        # Start shutdown in background thread
        def shutdown():
            time.sleep(2)
            log("üëã Application shutting down...")
            os._exit(0)
        
        Thread(target=shutdown, daemon=True).start()
        return jsonify({"success": True, "message": "Application terminating..."})
    except Exception as e:
        log(f"‚ùå Kill error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route("/health")
def health():
    return jsonify({"status": "running", "app_running": app_running})

if __name__ == "__main__":
    # Clear logs on startup
    clear_logs_on_startup()
    
    # Install psutil if not available
    try:
        import psutil
    except ImportError:
        log("üì¶ Installing psutil for system monitoring...")
        subprocess.run([sys.executable, "-m", "pip", "install", "psutil"], check=True)
        import psutil
    
    # Initialize balance
    current_balance = get_balance_from_api()
    
    # Start all threads
    Thread(target=worker, daemon=True).start()
    Thread(target=balance_updater, daemon=True).start()  # NEW: Auto-balance updater
    
    ip = socket.gethostbyname(socket.gethostname()) or "localhost"
    log(f"üöÄ ULTRA-FAST Content Analyzer Started")
    log(f"üìä Dashboard: http://{ip}:{CONFIG['port']}")
    log(f"‚è∞ Snapshots: Every {CONFIG['interval']} seconds")
    log(f"‚ö° Auto-GPT: Every {CONFIG['gpt_interval']} seconds when content changes")
    log(f"üí∞ Balance Updates: Automatic every {CONFIG['balance_interval']} seconds")
    log(f"üìù Aggregate Log: {CONFIG['log_dir']}/{CONFIG['aggregate_log']}")
    log(f"üí∞ OpenAI Balance: {get_openai_balance()}")
    log("üíÄ KILL SWITCH: Fixed and working")
    log("üöÄ INSTANT MANUAL PROMPTS: Working")
    log("üìã COPY ALL TEXT: Working")
    log("üîÑ AUTO-BALANCE: Enabled")
    if gpt_enabled:
        log(f"üß† Model: {CONFIG['openai_model']}")
        log("üéØ MODE: Auto-GPT + Instant manual prompts")
    
    try:
        app.run(host="0.0.0.0", port=CONFIG["port"], debug=False, threaded=True)
    except KeyboardInterrupt:
        log("üëã Application stopped by user")
    finally:
        worker_running = False
        log("üëã Application shutdown complete")