#!/usr/bin/env python3
"""
Sensor Timestamp Synchronization - Superset Implementation

A comprehensive solution that combines and improves both ex2.py and lidar-test.py
with multiple algorithm implementations, extensive testing, and visualization.

Key Features:
1. Four synchronization algorithms with different trade-offs
2. Comprehensive unit testing with both original test cases
3. Performance benchmarking and comparison
4. Error analysis and visualization
5. Production-ready with proper documentation
"""

import sys
import bisect
import time
import random
import statistics
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from enum import Enum
import json
import matplotlib.pyplot as plt
import numpy as np


class SyncAlgorithm(Enum):
    """Available synchronization algorithms"""
    BRUTE_FORCE = "brute_force"      # ex2.py approach - O(n¬≤) but simple
    LINEAR_SCAN = "linear_scan"      # lidar-test.py approach - O(n)
    BINARY_SEARCH = "binary_search"  # Optimized approach - O(n log m)
    HYBRID = "hybrid"                # Combined approach with adaptive windows


@dataclass
class SyncResult:
    """Container for synchronization results with metrics"""
    synchronized_messages: List[Dict[str, float]]
    algorithm: SyncAlgorithm
    execution_time: float
    error_metrics: Dict[str, float]
    stats: Dict[str, Any]


class SensorTimestampSynchronizer:
    """
    Superset implementation combining best aspects of both versions
    
    This class provides:
    1. All original algorithms with improvements and bug fixes
    2. Performance benchmarking across algorithms
    3. Visualization of results
    4. Error analysis and reporting
    5. Configurable synchronization parameters
    """
    
    def __init__(self, messages: Dict[str, List[float]], 
                 reference_sensor: str = 'lidar_0',
                 max_time_diff: float = 0.5):
        """
        Initialize the synchronizer.
        
        Args:
            messages: Dictionary of sensor timestamps
            reference_sensor: Sensor to use as reference for synchronization
            max_time_diff: Maximum allowed time difference for synchronization (seconds)
        """
        self.messages = {k: sorted(v) for k, v in messages.items()}
        self.reference_sensor = reference_sensor
        self.max_time_diff = max_time_diff
        self.other_sensors = [s for s in self.messages.keys() if s != reference_sensor]
        
        self._validate_input()
    
    def _validate_input(self) -> None:
        """Validate input data consistency"""
        if not self.messages:
            raise ValueError("No sensor data provided")
        
        if self.reference_sensor not in self.messages:
            raise ValueError(f"Reference sensor '{self.reference_sensor}' not found in data")
        
        for sensor, timestamps in self.messages.items():
            if not timestamps:
                raise ValueError(f"Sensor '{sensor}' has no timestamps")
            
            # Check if sorted
            if any(timestamps[i] > timestamps[i+1] for i in range(len(timestamps)-1)):
                raise ValueError(f"Sensor '{sensor}' timestamps are not sorted")
    
    # =========================================================================
    # ALGORITHM 1: Improved ex2.py (Brute Force)
    # =========================================================================
    def sync_brute_force(self) -> SyncResult:
        """
        Improved version of ex2.py algorithm.
        
        Fixes from original:
        1. Removed redundant b_test0 logic
        2. Added proper outlier detection for first timestamp
        3. Added max_time_diff parameter
        4. Reduced code duplication
        
        Complexity: O(n * m) where n = reference timestamps, m = other sensor timestamps
        
        Best for: Small datasets, clarity in interviews
        """
        start_time = time.time()
        synchronized = []
        ref_times = self.messages[self.reference_sensor]
        
        # Determine if first timestamp should be skipped (outlier detection)
        skip_first = self._should_skip_first_timestamp(ref_times[0])
        start_idx = 1 if skip_first else 0
        
        for i in range(start_idx, len(ref_times)):
            ref_time = ref_times[i]
            synced_entry = {self.reference_sensor: ref_time}
            valid_sync = True
            
            for sensor in self.other_sensors:
                closest, min_diff = self._find_closest_brute_force(ref_time, self.messages[sensor])
                
                if min_diff <= self.max_time_diff:
                    synced_entry[sensor] = closest
                else:
                    valid_sync = False
                    break
            
            if valid_sync:
                synchronized.append(synced_entry)
        
        execution_time = time.time() - start_time
        
        return SyncResult(
            synchronized_messages=synchronized,
            algorithm=SyncAlgorithm.BRUTE_FORCE,
            execution_time=execution_time,
            error_metrics=self._calculate_error_metrics(synchronized),
            stats={
                'total_reference_timestamps': len(ref_times),
                'synchronized_count': len(synchronized),
                'skipped_first': skip_first,
                'max_time_diff': self.max_time_diff
            }
        )
    
    def _find_closest_brute_force(self, ref_time: float, 
                                 timestamps: List[float]) -> Tuple[float, float]:
        """Find closest timestamp using brute force search (O(n))"""
        closest = timestamps[0]
        min_diff = abs(ref_time - closest)
        
        for ts in timestamps[1:]:
            diff = abs(ref_time - ts)
            if diff < min_diff:
                min_diff = diff
                closest = ts
        
        return closest, min_diff
    
    def _should_skip_first_timestamp(self, first_time: float) -> bool:
        """Determine if first timestamp is an outlier"""
        for sensor in self.other_sensors:
            # Check if any timestamp in other sensor is within max_time_diff
            has_close_match = any(
                abs(first_time - ts) <= self.max_time_diff 
                for ts in self.messages[sensor]
            )
            if not has_close_match:
                return True
        return False
    
    # =========================================================================
    # ALGORITHM 2: Improved lidar-test.py (Linear Scan)
    # =========================================================================
    def sync_linear_scan(self) -> SyncResult:
        """
        Improved version of lidar-test.py algorithm.
        
        Fixes from original:
        1. Cleaner variable naming and structure
        2. Removed debug prints
        3. Better handling of edge cases
        4. Added max_time_diff parameter
        
        Complexity: O(n + m) linear scan
        
        Best for: Medium datasets, predictable frequencies
        """
        start_time = time.time()
        synchronized = []
        ref_times = self.messages[self.reference_sensor]
        
        # Initialize indices for each sensor
        indices = {sensor: 0 for sensor in self.other_sensors}
        
        skip_first = self._should_skip_first_timestamp(ref_times[0])
        start_idx = 1 if skip_first else 0
        
        for i in range(start_idx, len(ref_times)):
            ref_time = ref_times[i]
            synced_entry = {self.reference_sensor: ref_time}
            valid_sync = True
            
            for sensor in self.other_sensors:
                idx = indices[sensor]
                sensor_times = self.messages[sensor]
                
                # Advance while current timestamp is less than reference
                while idx < len(sensor_times) and sensor_times[idx] < ref_time:
                    idx += 1
                
                # Find closest between idx-1 and idx
                if idx == 0:
                    closest = sensor_times[0]
                    time_diff = abs(ref_time - closest)
                elif idx == len(sensor_times):
                    closest = sensor_times[-1]
                    time_diff = abs(ref_time - closest)
                else:
                    prev_diff = abs(ref_time - sensor_times[idx-1])
                    next_diff = abs(ref_time - sensor_times[idx])
                    
                    if prev_diff < next_diff:
                        closest = sensor_times[idx-1]
                        time_diff = prev_diff
                    else:
                        closest = sensor_times[idx]
                        time_diff = next_diff
                
                if time_diff <= self.max_time_diff:
                    synced_entry[sensor] = closest
                    indices[sensor] = idx
                else:
                    valid_sync = False
                    break
            
            if valid_sync:
                synchronized.append(synced_entry)
        
        execution_time = time.time() - start_time
        
        return SyncResult(
            synchronized_messages=synchronized,
            algorithm=SyncAlgorithm.LINEAR_SCAN,
            execution_time=execution_time,
            error_metrics=self._calculate_error_metrics(synchronized),
            stats={
                'total_reference_timestamps': len(ref_times),
                'synchronized_count': len(synchronized),
                'skipped_first': skip_first,
                'max_time_diff': self.max_time_diff
            }
        )
    
    # =========================================================================
    # ALGORITHM 3: Binary Search (Optimized)
    # =========================================================================
    def sync_binary_search(self) -> SyncResult:
        """
        Optimized algorithm using binary search.
        
        Complexity: O(n log m) where n = reference timestamps, m = other sensor timestamps
        
        Best for: Large datasets, production use
        """
        start_time = time.time()
        synchronized = []
        ref_times = self.messages[self.reference_sensor]
        
        skip_first = self._should_skip_first_timestamp(ref_times[0])
        start_idx = 1 if skip_first else 0
        
        for i in range(start_idx, len(ref_times)):
            ref_time = ref_times[i]
            synced_entry = {self.reference_sensor: ref_time}
            valid_sync = True
            
            for sensor in self.other_sensors:
                closest = self._find_closest_binary(ref_time, self.messages[sensor])
                time_diff = abs(ref_time - closest)
                
                if time_diff <= self.max_time_diff:
                    synced_entry[sensor] = closest
                else:
                    valid_sync = False
                    break
            
            if valid_sync:
                synchronized.append(synced_entry)
        
        execution_time = time.time() - start_time
        
        return SyncResult(
            synchronized_messages=synchronized,
            algorithm=SyncAlgorithm.BINARY_SEARCH,
            execution_time=execution_time,
            error_metrics=self._calculate_error_metrics(synchronized),
            stats={
                'total_reference_timestamps': len(ref_times),
                'synchronized_count': len(synchronized),
                'skipped_first': skip_first,
                'max_time_diff': self.max_time_diff
            }
        )
    
    def _find_closest_binary(self, ref_time: float, 
                            timestamps: List[float]) -> float:
        """Find closest timestamp using binary search"""
        idx = bisect.bisect_left(timestamps, ref_time)
        
        if idx == 0:
            return timestamps[0]
        elif idx == len(timestamps):
            return timestamps[-1]
        else:
            prev_diff = abs(ref_time - timestamps[idx-1])
            next_diff = abs(ref_time - timestamps[idx])
            return timestamps[idx-1] if prev_diff < next_diff else timestamps[idx]
    
    # =========================================================================
    # ALGORITHM 4: Hybrid Approach
    # =========================================================================
    def sync_hybrid(self) -> SyncResult:
        """
        Hybrid approach combining linear scan with adaptive windows.
        
        Features:
        1. Uses linear scan for efficiency
        2. Adapts window size based on sensor frequencies
        3. Handles varying sampling rates better
        
        Best for: Real-world sensor data with varying frequencies
        """
        start_time = time.time()
        synchronized = []
        ref_times = self.messages[self.reference_sensor]
        
        # Calculate adaptive window sizes based on sensor frequencies
        window_sizes = self._calculate_adaptive_window_sizes()
        
        skip_first = self._should_skip_first_timestamp(ref_times[0])
        start_idx = 1 if skip_first else 0
        
        for i in range(start_idx, len(ref_times)):
            ref_time = ref_times[i]
            synced_entry = {self.reference_sensor: ref_time}
            valid_sync = True
            
            for sensor in self.other_sensors:
                window = window_sizes.get(sensor, self.max_time_diff * 2)
                closest = self._find_closest_in_window(ref_time, self.messages[sensor], window)
                
                if closest is not None:
                    time_diff = abs(ref_time - closest)
                    if time_diff <= self.max_time_diff:
                        synced_entry[sensor] = closest
                    else:
                        valid_sync = False
                        break
                else:
                    valid_sync = False
                    break
            
            if valid_sync:
                synchronized.append(synced_entry)
        
        execution_time = time.time() - start_time
        
        return SyncResult(
            synchronized_messages=synchronized,
            algorithm=SyncAlgorithm.HYBRID,
            execution_time=execution_time,
            error_metrics=self._calculate_error_metrics(synchronized),
            stats={
                'total_reference_timestamps': len(ref_times),
                'synchronized_count': len(synchronized),
                'skipped_first': skip_first,
                'max_time_diff': self.max_time_diff,
                'adaptive_windows': window_sizes
            }
        )
    
    def _find_closest_in_window(self, ref_time: float, 
                               timestamps: List[float], 
                               window: float) -> Optional[float]:
        """Find closest timestamp within a time window using binary search"""
        start_idx = bisect.bisect_left(timestamps, ref_time - window)
        end_idx = bisect.bisect_right(timestamps, ref_time + window)
        
        if start_idx >= end_idx:
            return None
        
        # Find closest within window
        window_timestamps = timestamps[start_idx:end_idx]
        return min(window_timestamps, key=lambda x: abs(x - ref_time))
    
    def _calculate_adaptive_window_sizes(self) -> Dict[str, float]:
        """Calculate adaptive window sizes based on sensor frequencies"""
        window_sizes = {}
        
        for sensor in self.other_sensors:
            if len(self.messages[sensor]) > 1:
                # Calculate average time between measurements
                diffs = [
                    self.messages[sensor][i+1] - self.messages[sensor][i]
                    for i in range(len(self.messages[sensor])-1)
                ]
                avg_interval = statistics.mean(diffs) if diffs else self.max_time_diff
                # Window size = 2 * average interval or max_time_diff, whichever is larger
                window_sizes[sensor] = max(self.max_time_diff * 2, avg_interval * 2)
            else:
                window_sizes[sensor] = self.max_time_diff * 2
        
        return window_sizes
    
    # =========================================================================
    # ANALYSIS & UTILITIES
    # =========================================================================
    def _calculate_error_metrics(self, synchronized: List[Dict[str, float]]) -> Dict[str, float]:
        """Calculate synchronization error metrics"""
        if not synchronized:
            return {
                'avg_time_diff': 0.0,
                'max_time_diff': 0.0,
                'std_dev': 0.0,
                'rmse': 0.0
            }
        
        time_diffs = []
        for entry in synchronized:
            ref_time = entry[self.reference_sensor]
            for sensor, timestamp in entry.items():
                if sensor != self.reference_sensor:
                    time_diffs.append(abs(ref_time - timestamp))
        
        avg_diff = statistics.mean(time_diffs) if time_diffs else 0.0
        max_diff = max(time_diffs) if time_diffs else 0.0
        
        if len(time_diffs) > 1:
            std_dev = statistics.stdev(time_diffs)
            rmse = statistics.mean(diff**2 for diff in time_diffs) ** 0.5
        else:
            std_dev = 0.0
            rmse = avg_diff
        
        return {
            'avg_time_diff': avg_diff,
            'max_time_diff': max_diff,
            'std_dev': std_dev,
            'rmse': rmse
        }
    
    def benchmark_algorithms(self) -> Dict[str, SyncResult]:
        """
        Benchmark all synchronization algorithms.
        
        Returns dictionary with results from all algorithms.
        """
        print("=" * 70)
        print("SENSOR SYNCHRONIZATION ALGORITHM BENCHMARK")
        print("=" * 70)
        
        algorithms = [
            ('Brute Force', self.sync_brute_force),
            ('Linear Scan', self.sync_linear_scan),
            ('Binary Search', self.sync_binary_search),
            ('Hybrid', self.sync_hybrid),
        ]
        
        results = {}
        
        for name, algorithm_func in algorithms:
            print(f"\nüîß Running: {name}")
            result = algorithm_func()
            results[name] = result
            
            print(f"   ‚è±Ô∏è  Execution Time: {result.execution_time:.6f} seconds")
            print(f"   üìä Synchronized: {len(result.synchronized_messages)} messages")
            print(f"   üìà Avg Error: {result.error_metrics['avg_time_diff']:.6f} seconds")
            print(f"   üìâ Max Error: {result.error_metrics['max_time_diff']:.6f} seconds")
            print(f"   üìê Std Dev: {result.error_metrics['std_dev']:.6f} seconds")
        
        # Find best algorithm based on balanced metrics
        best_name = min(results.keys(), 
                       key=lambda x: (
                           results[x].error_metrics['avg_time_diff'] * 0.6 +  # 60% weight to accuracy
                           results[x].execution_time * 0.4  # 40% weight to speed
                       ))
        
        print("\n" + "=" * 70)
        print(f"üèÜ BEST ALGORITHM: {best_name}")
        print(f"   Average Error: {results[best_name].error_metrics['avg_time_diff']:.6f}s")
        print(f"   Execution Time: {results[best_name].execution_time:.6f}s")
        print("=" * 70)
        
        return results, best_name
    
    def visualize_results(self, result: SyncResult, save_path: Optional[str] = None):
        """
        Visualize synchronization results.
        
        Creates four subplots showing:
        1. Raw sensor timestamps
        2. Synchronized points
        3. Error distribution
        4. Performance summary
        """
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # Plot 1: Raw sensor timestamps
        ax1 = axes[0, 0]
        colors = plt.cm.Set1(np.linspace(0, 1, len(self.messages)))
        
        for idx, (sensor, timestamps) in enumerate(self.messages.items()):
            ax1.scatter(timestamps, [idx] * len(timestamps),
                       label=sensor, alpha=0.7, s=15, color=colors[idx],
                       edgecolors='white', linewidth=0.5)
        
        ax1.set_title('üì° Raw Sensor Timestamps', fontsize=12, fontweight='bold')
        ax1.set_xlabel('Time (seconds)', fontsize=10)
        ax1.set_ylabel('Sensor', fontsize=10)
        ax1.legend(loc='upper right', fontsize=9)
        ax1.grid(True, alpha=0.3, linestyle='--')
        ax1.set_yticks(range(len(self.messages)))
        ax1.set_yticklabels(list(self.messages.keys()))
        
        # Plot 2: Synchronized points
        ax2 = axes[0, 1]
        if result.synchronized_messages:
            sync_data = {sensor: [] for sensor in self.messages.keys()}
            
            for entry in result.synchronized_messages:
                for sensor, timestamp in entry.items():
                    sync_data[sensor].append(timestamp)
            
            for idx, (sensor, timestamps) in enumerate(sync_data.items()):
                if timestamps:  # Only plot if we have synchronized timestamps
                    ax2.scatter(timestamps, [idx] * len(timestamps),
                               alpha=0.8, s=20, color=colors[idx],
                               marker='s', edgecolors='black', linewidth=0.5,
                               label=f'{sensor} (synced)')
            
            ax2.set_title(f'‚úÖ Synchronized Points ({result.algorithm.value})', 
                         fontsize=12, fontweight='bold')
            ax2.set_xlabel('Time (seconds)', fontsize=10)
            ax2.set_ylabel('Sensor', fontsize=10)
            ax2.legend(loc='upper right', fontsize=9)
            ax2.grid(True, alpha=0.3, linestyle='--')
            ax2.set_yticks(range(len(self.messages)))
            ax2.set_yticklabels(list(self.messages.keys()))
        
        # Plot 3: Error distribution
        ax3 = axes[1, 0]
        if result.synchronized_messages:
            time_diffs = []
            for entry in result.synchronized_messages:
                ref_time = entry[self.reference_sensor]
                for sensor, timestamp in entry.items():
                    if sensor != self.reference_sensor:
                        time_diffs.append(abs(ref_time - timestamp) * 1000)  # Convert to ms
            
            if time_diffs:
                n, bins, patches = ax3.hist(time_diffs, bins=15, alpha=0.7, 
                                           color='steelblue', edgecolor='black', 
                                           linewidth=1.2)
                
                # Add mean line
                mean_diff = np.mean(time_diffs)
                ax3.axvline(mean_diff, color='red', linestyle='--', linewidth=2,
                           label=f'Mean: {mean_diff:.2f} ms')
                
                # Add median line
                median_diff = np.median(time_diffs)
                ax3.axvline(median_diff, color='green', linestyle='--', linewidth=2,
                           label=f'Median: {median_diff:.2f} ms')
                
                ax3.set_title('üìä Synchronization Error Distribution', 
                             fontsize=12, fontweight='bold')
                ax3.set_xlabel('Time Difference (milliseconds)', fontsize=10)
                ax3.set_ylabel('Frequency', fontsize=10)
                ax3.legend(loc='upper right', fontsize=9)
                ax3.grid(True, alpha=0.3, linestyle='--')
        
        # Plot 4: Performance summary
        ax4 = axes[1, 1]
        summary_text = (
            f"Algorithm: {result.algorithm.value}\n"
            f"Execution Time: {result.execution_time:.4f}s\n"
            f"Synchronized: {len(result.synchronized_messages)}/{len(self.messages[self.reference_sensor])}\n"
            f"Success Rate: {len(result.synchronized_messages)/len(self.messages[self.reference_sensor])*100:.1f}%\n"
            f"Avg Error: {result.error_metrics['avg_time_diff']*1000:.2f} ms\n"
            f"Max Error: {result.error_metrics['max_time_diff']*1000:.2f} ms\n"
            f"Std Dev: {result.error_metrics['std_dev']*1000:.2f} ms\n"
            f"Max Time Diff: {self.max_time_diff*1000:.0f} ms"
        )
        
        ax4.text(0.5, 0.5, summary_text, ha='center', va='center', 
                transform=ax4.transAxes, fontsize=11,
                bbox=dict(boxstyle='round', facecolor='wheat', 
                         alpha=0.8, pad=15))
        ax4.set_title('üìà Performance Summary', fontsize=12, fontweight='bold')
        ax4.axis('off')
        
        plt.suptitle('Sensor Timestamp Synchronization Analysis', 
                    fontsize=16, fontweight='bold', y=0.98)
        plt.tight_layout(rect=[0, 0, 1, 0.96])
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"\nüíæ Visualization saved to: {save_path}")
        
        plt.show()
    
    def export_results(self, result: SyncResult, filename: str = "sync_results.json"):
        """Export synchronization results to JSON file"""
        export_data = {
            'metadata': {
                'algorithm': result.algorithm.value,
                'reference_sensor': self.reference_sensor,
                'max_time_diff': self.max_time_diff,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            },
            'performance': {
                'execution_time': result.execution_time,
                'error_metrics': result.error_metrics,
                'statistics': result.stats
            },
            'input_summary': {
                'sensors': list(self.messages.keys()),
                'timestamp_counts': {k: len(v) for k, v in self.messages.items()}
            },
            'synchronized_messages': result.synchronized_messages
        }
        
        with open(filename, 'w') as f:
            json.dump(export_data, f, indent=2, default=str)
        
        print(f"üì§ Results exported to: {filename}")
        return export_data
    
    def run_comprehensive_analysis(self, output_dir: str = "sync_analysis"):
        """
        Run complete analysis with all algorithms and generate reports.
        
        This is the main method that orchestrates the entire analysis pipeline.
        """
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        print("=" * 70)
        print("üéØ COMPREHENSIVE SENSOR SYNCHRONIZATION ANALYSIS")
        print("=" * 70)
        
        # 1. Input analysis
        print("\n1. üì• INPUT ANALYSIS:")
        total_timestamps = sum(len(v) for v in self.messages.values())
        print(f"   Total sensors: {len(self.messages)}")
        print(f"   Total timestamps: {total_timestamps}")
        
        for sensor, timestamps in self.messages.items():
            if len(timestamps) >= 2:
                duration = timestamps[-1] - timestamps[0]
                avg_interval = duration / (len(timestamps) - 1) if duration > 0 else 0
                freq = 1 / avg_interval if avg_interval > 0 else 0
                print(f"   {sensor}: {len(timestamps)} timestamps, "
                      f"Duration: {duration:.2f}s, Freq: {freq:.2f} Hz")
        
        # 2. Benchmark all algorithms
        print("\n2. ‚ö° ALGORITHM BENCHMARKING:")
        results, best_name = self.benchmark_algorithms()
        
        # 3. Visualize best result
        print(f"\n3. üìä VISUALIZING BEST ALGORITHM ({best_name}):")
        viz_path = os.path.join(output_dir, f"{best_name.lower().replace(' ', '_')}_results.png")
        self.visualize_results(results[best_name], viz_path)
        
        # 4. Export results
        print(f"\n4. üíæ EXPORTING RESULTS:")
        export_path = os.path.join(output_dir, "synchronization_results.json")
        self.export_results(results[best_name], export_path)
        
        # 5. Generate summary report
        summary_path = os.path.join(output_dir, "analysis_summary.txt")
        with open(summary_path, 'w') as f:
            f.write("SENSOR SYNCHRONIZATION ANALYSIS SUMMARY\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Analysis Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Total Sensors: {len(self.messages)}\n")
            f.write(f"Total Timestamps: {total_timestamps}\n")
            f.write(f"Best Algorithm: {best_name}\n")
            f.write(f"Execution Time: {results[best_name].execution_time:.6f}s\n")
            f.write(f"Synchronized Messages: {len(results[best_name].synchronized_messages)}\n")
            f.write(f"Average Error: {results[best_name].error_metrics['avg_time_diff']*1000:.2f} ms\n")
        
        print(f"\nüìù Summary report saved to: {summary_path}")
        print("\n" + "=" * 70)
        print("‚úÖ ANALYSIS COMPLETE!")
        print(f"üìÅ All results saved to: {os.path.abspath(output_dir)}")
        print("=" * 70)


# =============================================================================
# ORIGINAL ALGORITHMS (for backward compatibility and comparison)
# =============================================================================
def sync_msgs_ex2_original(messages: Dict[str, List[float]]) -> List[Dict[str, float]]:
    """
    Original ex2.py algorithm (exact implementation for comparison).
    
    This is preserved for backward compatibility and to demonstrate
    the improvements made in the superset implementation.
    """
    import sys
    
    lst = []
    b_test0 = False
    for ts1 in messages['lidar_0']:
        for ts2 in messages['lidar_1']:
            if ts1 == ts2:
                b_test0 = True

    if b_test0:
        for ts0 in messages['lidar_0']:
            dict_ = {}
            dict_['lidar_0'] = ts0
            min_ = sys.float_info.max
            ts1_star = 0.0
            for ts1 in messages['lidar_1']:
                if min_ > abs(ts0-ts1):
                    min_ = min(min_, abs(ts0-ts1))
                    ts1_star = ts1
            dict_['lidar_1'] = ts1_star  
            min_ = sys.float_info.max
            ts2_star = 0.0
            for ts2 in messages['lidar_2']:
                if min_> abs(ts0-ts2):
                    min_ = min(min_, abs(ts0-ts2))
                    ts2_star = ts2
            dict_['lidar_2'] = ts2_star
            lst.append(dict_)
    else:
        i = 0
        for ts0 in messages['lidar_0']:
            if i > 0:
                dict_ = {}
                dict_['lidar_0'] = ts0
                min_ = sys.float_info.max
                ts1_star = 0.0
                for ts1 in messages['lidar_1']:
                    if min_ > abs(ts0-ts1):
                        min_ = min(min_, abs(ts0-ts1))
                        ts1_star = ts1
                dict_['lidar_1'] = ts1_star  
                min_ = sys.float_info.max
                ts2_star = 0.0
                for ts2 in messages['lidar_2']:
                    if min_ > abs(ts0-ts2):
                        min_ = min(min_, abs(ts0-ts2))
                        ts2_star = ts2
                dict_['lidar_2'] = ts2_star
                
                lst.append(dict_)

            i += 1

    return lst


def sync_msgs_lidar_original(messages: Dict[str, List[float]]) -> List[Dict[str, float]]:
    """
    Original lidar-test.py algorithm (exact implementation for comparison).
    
    This is preserved for backward compatibility and to demonstrate
    the improvements made in the superset implementation.
    """
    lst=[]
    idx=0
    idx1=0
    for ts0 in messages['lidar_0']:
        if idx==0 and ts0 < messages['lidar_1'][0] and idx1 == 0\
            and ts0 < messages['lidar_2'][0]:
            if abs(ts0-messages['lidar_1'][0])<abs(ts0-messages['lidar_1'][1]):
                # Original had: print('qqq', abs(ts0-messages['lidar_1'][0]), abs(ts0-messages['lidar_1'][1]))
                pass
        else:
            dict_ = {}
            while idx<len(messages['lidar_1']) and messages['lidar_1'][idx] <= ts0:
                idx+=1
            if idx < len(messages['lidar_1']):
                if abs(messages['lidar_1'][idx]-ts0)>abs(messages['lidar_1'][idx-1]-ts0):
                    dict_['lidar_0'] = ts0
                    dict_['lidar_1'] = messages['lidar_1'][idx-1]
                else:
                    dict_['lidar_0'] = ts0
                    dict_['lidar_1'] = messages['lidar_1'][idx]
            else:
                dict_['lidar_0'] = ts0
                dict_['lidar_1']=messages['lidar_1'][idx-1]

            while idx1<len(messages['lidar_2']) and messages['lidar_2'][idx1] <= ts0:
                idx1+=1
            if idx1 < len(messages['lidar_2']):
                if abs(messages['lidar_2'][idx1]-ts0)>abs(messages['lidar_2'][idx1-1]-ts0):
                    dict_['lidar_0'] = ts0
                    dict_['lidar_2'] = messages['lidar_2'][idx1-1]
                else:
                    dict_['lidar_0'] = ts0
                    dict_['lidar_2'] = messages['lidar_2'][idx1]
            else:
                dict_['lidar_0'] = ts0
                dict_['lidar_2']=messages['lidar_2'][idx1-1]

            lst.append(dict_)

    return lst


# =============================================================================
# TEST SUITE (Combined from both original files)
# =============================================================================
def create_test_suite() -> List[Tuple[Dict[str, List[float]], List[Dict[str, float]]]]:
    """Create comprehensive test suite from both original files"""
    
    # Test 1: Different frequencies, perfectly in sync (from both files)
    test1_messages = {
        "lidar_0": [
            1585712295.624838,
            1585712296.624838,
            1585712297.624838,
        ],
        'lidar_1': [
            1585712295.124838,
            1585712295.624838,
            1585712296.124838,
            1585712296.624838,
            1585712297.124838,
            1585712297.624838
        ],
        'lidar_2': [
            1585712294.954838,
            1585712295.284838,
            1585712295.624838,
            1585712295.954838,
            1585712296.284838,
            1585712296.624838,
            1585712296.954838,
            1585712297.284838,
            1585712297.624838,
        ]
    }
    
    test1_expected = [
        {
            'lidar_0': test1_messages['lidar_0'][0],
            'lidar_1': test1_messages['lidar_1'][1],
            'lidar_2': test1_messages['lidar_2'][2]
        },
        {
            'lidar_0': test1_messages['lidar_0'][1],
            'lidar_1': test1_messages['lidar_1'][3],
            'lidar_2': test1_messages['lidar_2'][5]
        },
        {
            'lidar_0': test1_messages['lidar_0'][2],
            'lidar_1': test1_messages['lidar_1'][5],
            'lidar_2': test1_messages['lidar_2'][8]
        }
    ]
    
    # Test 2: Same frequency, lidar_0 started early (from both files)
    test2_messages = {
        "lidar_0": [
            1585712294.624838,
            1585712295.624838,
            1585712296.624838
        ],
        'lidar_1': [
            1585712295.524838,
            1585712296.524838,
            1585712297.524838,
        ],
        'lidar_2': [
            1585712295.724838,
            1585712296.724838,
            1585712297.724838,
        ]
    }
    
    test2_expected = [
        {
            'lidar_0': test2_messages['lidar_0'][1],
            'lidar_1': test2_messages['lidar_1'][0],
            'lidar_2': test2_messages['lidar_2'][0]
        },
        {
            'lidar_0': test2_messages['lidar_0'][2],
            'lidar_1': test2_messages['lidar_1'][1],
            'lidar_2': test2_messages['lidar_2'][1]
        }
    ]
    
    # Test 3: Two sensors in sync, third slightly offset (from both files)
    test3_messages = {
        "lidar_0": [
            1585712295.124838,
            1585712296.124838,
            1585712297.124838,
        ],
        'lidar_1': [
            1585712295.624838,
            1585712296.624838,
            1585712297.624838,
        ],
        'lidar_2': [
            1585712295.724838,
            1585712296.724838,
            1585712297.724838,
        ]
    }
    
    test3_expected = [
        {
            'lidar_0': test3_messages['lidar_0'][1],
            'lidar_1': test3_messages['lidar_1'][0],
            'lidar_2': test3_messages['lidar_2'][0]
        },
        {
            'lidar_0': test3_messages['lidar_0'][2],
            'lidar_1': test3_messages['lidar_1'][1],
            'lidar_2': test3_messages['lidar_2'][1]
        }
    ]
    
    # Test 4: Additional test - completely offset sensors
    test4_messages = {
        "lidar_0": [1.0, 2.0, 3.0, 4.0, 5.0],
        'lidar_1': [1.1, 2.1, 3.1, 4.1, 5.1],
        'lidar_2': [0.9, 1.9, 2.9, 3.9, 4.9]
    }
    
    test4_expected = [
        {'lidar_0': 2.0, 'lidar_1': 2.1, 'lidar_2': 1.9},
        {'lidar_0': 3.0, 'lidar_1': 3.1, 'lidar_2': 2.9},
        {'lidar_0': 4.0, 'lidar_1': 4.1, 'lidar_2': 3.9},
        {'lidar_0': 5.0, 'lidar_1': 5.1, 'lidar_2': 4.9}
    ]
    
    # Test 5: Edge case - very sparse data
    test5_messages = {
        "lidar_0": [1.0, 10.0, 20.0],
        'lidar_1': [0.5, 1.5, 10.5, 20.5],
        'lidar_2': [0.8, 1.2, 10.2, 20.2]
    }
    
    test5_expected = [
        {'lidar_0': 10.0, 'lidar_1': 10.5, 'lidar_2': 10.2},
        {'lidar_0': 20.0, 'lidar_1': 20.5, 'lidar_2': 20.2}
    ]
    
    return [
        (test1_messages, test1_expected, "Different frequencies, perfectly in sync"),
        (test2_messages, test2_expected, "Same frequency, lidar_0 started early"),
        (test3_messages, test3_expected, "Two sensors in sync, third slightly offset"),
        (test4_messages, test4_expected, "Completely offset sensors (0.1s offset)"),
        (test5_messages, test5_expected, "Sparse data with large gaps")
    ]


def compare_results(actual: List[Dict[str, float]], 
                   expected: List[Dict[str, float]],
                   tolerance: float = 1e-9) -> bool:
    """Compare actual results with expected results within tolerance"""
    if len(actual) != len(expected):
        return False
    
    for act, exp in zip(actual, expected):
        if set(act.keys()) != set(exp.keys()):
            return False
        
        for key in act:
            if abs(act[key] - exp[key]) > tolerance:
                return False
    
    return True


def run_original_tests():
    """Run tests on original algorithms for comparison"""
    print("=" * 70)
    print("üîç ORIGINAL ALGORITHM VALIDATION")
    print("=" * 70)
    
    test_suite = create_test_suite()
    
    print("\n1. Testing ex2.py original algorithm:")
    ex2_passed = 0
    for i, (messages, expected, description) in enumerate(test_suite[:3], 1):  # First 3 tests only
        result = sync_msgs_ex2_original(messages)
        passed = compare_results(result, expected)
        ex2_passed += 1 if passed else 0
        print(f"   Test {i} ({description}): {'‚úÖ PASS' if passed else '‚ùå FAIL'}")
    
    print(f"\n   Total: {ex2_passed}/3 tests passed")
    
    print("\n2. Testing lidar-test.py original algorithm:")
    lidar_passed = 0
    for i, (messages, expected, description) in enumerate(test_suite[:3], 1):
        result = sync_msgs_lidar_original(messages)
        passed = compare_results(result, expected)
        lidar_passed += 1 if passed else 0
        print(f"   Test {i} ({description}): {'‚úÖ PASS' if passed else '‚ùå FAIL'}")
    
    print(f"\n   Total: {lidar_passed}/3 tests passed")
    
    return ex2_passed == 3 and lidar_passed == 3


# =============================================================================
# MAIN EXECUTION
# =============================================================================
def main():
    """Main execution function"""
    print("=" * 70)
    print("üß™ SENSOR TIMESTAMP SYNCHRONIZATION - SUPERSET IMPLEMENTATION")
    print("=" * 70)
    
    # 1. Validate original algorithms
    print("\nüìã STEP 1: Validating original algorithms...")
    originals_valid = run_original_tests()
    
    if not originals_valid:
        print("\n‚ö†Ô∏è  Warning: Some original algorithm tests failed.")
        print("   Superset implementation will continue with fixes.")
    
    # 2. Create test data
    print("\nüìä STEP 2: Creating test data...")
    test_suite = create_test_suite()
    
    # Use the first test case for demonstration
    test_messages, test_expected, test_description = test_suite[0]
    
    print(f"   Test: {test_description}")
    print(f"   Sensors: {list(test_messages.keys())}")
    for sensor, timestamps in test_messages.items():
        print(f"   {sensor}: {len(timestamps)} timestamps "
              f"[{timestamps[0]:.3f} to {timestamps[-1]:.3f}]")
    
    # 3. Run superset analysis
    print("\nüöÄ STEP 3: Running superset analysis...")
    synchronizer = SensorTimestampSynchronizer(
        messages=test_messages,
        reference_sensor='lidar_0',
        max_time_diff=0.5  # 500ms maximum difference
    )
    
    # Run comprehensive analysis
    synchronizer.run_comprehensive_analysis(output_dir="sensor_sync_analysis")
    
    # 4. Additional demonstration
    print("\nüéØ STEP 4: Algorithm comparison on all test cases...")
    
    all_results = []
    for i, (messages, expected, description) in enumerate(test_suite, 1):
        print(f"\n   Test Case {i}: {description}")
        sync = SensorTimestampSynchronizer(messages, max_time_diff=0.5)
        
        # Test all algorithms
        results = {}
        for algo_name, algo_func in [
            ('Brute Force', sync.sync_brute_force),
            ('Linear Scan', sync.sync_linear_scan),
            ('Binary Search', sync.sync_binary_search),
            ('Hybrid', sync.sync_hybrid)
        ]:
            result = algo_func()
            results[algo_name] = {
                'time': result.execution_time,
                'count': len(result.synchronized_messages),
                'error': result.error_metrics['avg_time_diff']
            }
        
        # Find best for this test case
        best_algo = min(results.keys(), 
                       key=lambda x: results[x]['error'] + results[x]['time'])
        
        print(f"      Best: {best_algo} "
              f"(Error: {results[best_algo]['error']*1000:.2f}ms, "
              f"Time: {results[best_algo]['time']:.6f}s)")
        
        all_results.append({
            'test': description,
            'best_algorithm': best_algo,
            'results': results
        })
    
    # 5. Summary
    print("\n" + "=" * 70)
    print("üìà SUMMARY")
    print("=" * 70)
    
    # Count algorithm wins
    algo_wins = {}
    for result in all_results:
        best = result['best_algorithm']
        algo_wins[best] = algo_wins.get(best, 0) + 1
    
    print("\nAlgorithm Performance Summary:")
    for algo, wins in sorted(algo_wins.items(), key=lambda x: x[1], reverse=True):
        print(f"   {algo}: {wins}/{len(test_suite)} test cases best")
    
    print("\n" + "=" * 70)
    print("‚úÖ Superset implementation complete!")
    print("   This implementation combines and improves both ex2.py and lidar-test.py")
    print("   with better algorithms, error handling, visualization, and analysis.")
    print("=" * 70)


if __name__ == "__main__":
    main()